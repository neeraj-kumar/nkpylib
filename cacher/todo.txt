Design for new version:
- deal with errors in the API
- caching many different functions and including function in the cache key
  - maybe backends can specify a prefix that gets prepended to all (or some?) keys
- different key_funcs
- runnable in background/async/futures/threads
- backends
  - sql db
- write-through vs write-back
- multiple backends can reuse same strategy?
- batchable
  - first input as list
  - multiple inputs as parallel lists
  - cartesian product of input args
  - one output per input
  - single output, with multiple in subkey
  - input as dict
  - output as dict
- decorable
- ignore certain args
- cache a list or dict:
  - figure out which are already cached and which aren't
  - where underlying function takes a batch
- something for imdb data dump updates -> either run function or read from db/cache?
- expiration criteria
  - time (either relative from now, or absolute time)
  - count
  - memory
  - other?
- single-value cache with different keys
  - e.g. the embeddings cache which checks for current normed, scale_mean, scale_std
- ignore cache for individual calls
- archival
- delay + variance
- different formats:
  - pickle
- different backing stores - mem, fs, lmdb, numpylmdb
- one file per key, or one file overall, or ...?
- stats/timing
- prefetch?
- caching binary files (e.g. web fetch request)
- per-host timers (like in make_request)?
- works on class methods (how to check for other instance var dependencies?)
- store revisions?
- named revisions?
- external dependencies:
    external_counter = 0
    @cache(depends_on=lambda:[external_counter])
    def things_with_external(a,b,c):
        global external_counter
        from time import sleep; sleep(1) # <- simulating a long-running process
        return external_counter + a + b + c


error_on_missing controls whether a cache miss raises a CacheNotFound exception (when True) or returns the CACHE_MISS 
sentinel value (when False).                                                                                          

Reasons you might want error_on_missing=False:                                                                        

 1 When using the cache as an optimization but want to handle misses silently                                         
 2 When checking if something exists in cache without wanting to handle exceptions                                    
 3 When implementing a multi-level cache where misses should fall through to the next level                           
 4 When the cache is optional/best-effort and shouldn't affect program flow                                           

Reasons you might want error_on_missing=True:                                                                         

 1 To force explicit handling of cache misses                                                                         
 2 When cache misses indicate a programming error                                                                     
 3 When the cache is required for correct operation                                                                   
 4 To make it obvious where cache misses occur during development                                                     

The choice often depends on whether cache misses are exceptional conditions or normal operation in your use case.     
